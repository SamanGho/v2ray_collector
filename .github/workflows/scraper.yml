name: V2Ray Link Scraper

on:
  schedule:
    - cron: '*/9 * * * *'  # This will run every 5 minutes
  workflow_dispatch: # Allows manual triggering of the workflow

jobs:
  scrape:
    runs-on: ubuntu-latest

    steps:
    - name: Checkout repository
      uses: actions/checkout@v3

    - name: Set up Python
      uses: actions/setup-python@v3
      with:
        python-version: '3.x'  # Specify the version of Python 

    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install requests beautifulsoup4

    - name: Run the scraper script
      run: |
        python main.py  # Replace with the actual script name

    - name: Commit and push results
      run: |
        git config --global user.name "Saman"
        git config --global user.email "charoniv.charonv@gmail.com"
        git add v2ray_links.txt
        git commit -m "Update V2Ray links"
        git push
      env:
        GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
